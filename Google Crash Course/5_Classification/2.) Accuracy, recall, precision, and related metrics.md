
Accuracy means NET RIGHT / TOTAL

$$
\text{Accuracy} = \frac{TP + TN}{TP + TN + FP + FN}
$$

T*P = +ve * +ve = +ve (use positive cases only)

$$
\text{Recall} = \frac{TP}{TP + FN}
$$

FP = -ve * +ve = -ve (use negative cases only)

$$
\text{False\ Positive\ Rate} = \frac{FP}{FP + TN}
$$

Precision = Positive cases probabilty 

$$
\text{Precision} = \frac{TP}{TP + FP}
$$



|Metric|Guidance|
|---|---|
|Accuracy|Use as a rough indicator of model training progress/convergence for balanced datasets.<br><br>For model performance, use only in combination with other metrics.<br><br>Avoid for imbalanced datasets. Consider using another metric.|
|Recall  <br>(True positive rate)|Use when false negatives are more expensive than false positives.|
|False positive rate|Use when false positives are more expensive than false negatives.|
|Precision|Use when it's very important for positive predictions to be accurate.|